# main.py (patched) â€” original code with safe media support (images URLs + audio transcription)
# - Keeps original threading/timer architecture intact
# - Adds support for: image URLs, audio URLs (transcribed to text)
# - If text+image+audio arrive within the batch window -> they are merged into one message to the assistant
# - Audio transcription uses OpenAI audio.transcriptions API (called in a thread); adjust model name if needed
# - Minimal, safe changes; all original code paths preserved

import os
import time
import json
import requests
import threading
import asyncio
import logging
from flask import Flask, request, jsonify
from openai import OpenAI
from pymongo import MongoClient
from datetime import datetime, timezone
from dotenv import load_dotenv

# --- Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', handlers=[logging.StreamHandler()])
logger = logging.getLogger(__name__)
load_dotenv()
logger.info("â–¶ï¸ [START] ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©.")

# --- Ù…ÙØ§ØªÙŠØ­ API ---
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ASSISTANT_ID_PREMIUM = os.getenv("ASSISTANT_ID_PREMIUM")
MONGO_URI = os.getenv("MONGO_URI")
MANYCHAT_API_KEY = os.getenv("MANYCHAT_API_KEY")
MANYCHAT_SECRET_KEY = os.getenv("MANYCHAT_SECRET_KEY")
logger.info("ğŸ”‘ [CONFIG] ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù…ÙØ§ØªÙŠØ­ API.")

# --- Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
try:
    client_db = MongoClient(MONGO_URI)
    db = client_db["multi_platform_bot"]
    sessions_collection = db["sessions"]
    logger.info("âœ… [DB] ØªÙ… Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­.")
except Exception as e:
    logger.critical(f"âŒ [DB] ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}", exc_info=True)
    exit()

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ---
app = Flask(__name__)
client = OpenAI(api_key=OPENAI_API_KEY)
logger.info("ğŸš€ [APP] ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ ØªØ·Ø¨ÙŠÙ‚ Flask Ùˆ OpenAI Client.")

# --- Ù…ØªØºÙŠØ±Ø§Øª Ø¹Ø§Ù„Ù…ÙŠØ© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ØºÙŠØ± Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø© ---
# pending_messages[user_id] = {"texts": [], "images": [], "audios": [], "session": session}
pending_messages = {}
message_timers = {}
processing_locks = {}
# Ø§Ù†ØªØ¸Ø± Ø«Ø§Ù†ÙŠØªÙŠÙ† Ø¨Ø¹Ø¯ Ø¢Ø®Ø± Ø±Ø³Ø§Ù„Ø© Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù‚Ø¨Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯ÙØ¹Ø©
BATCH_WAIT_TIME = 2.0 

# --- Ø¯ÙˆØ§Ù„ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¬Ù„Ø³Ø§Øª ---
def get_or_create_session_from_contact(contact_data):
    user_id = str(contact_data.get("id"))
    if not user_id:
        logger.error(f"âŒ [SESSION] Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ user_id ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {contact_data}")
        return None
        
    session = sessions_collection.find_one({"_id": user_id})
    now_utc = datetime.now(timezone.utc)
    
    main_platform = "Unknown"
    contact_source = contact_data.get("source", "").lower()
    if "instagram" in contact_source:
        main_platform = "Instagram"
    elif "facebook" in contact_source:
        main_platform = "Facebook"
    elif "ig_id" in contact_data and contact_data.get("ig_id"):
        main_platform = "Instagram"
    else:
        main_platform = "Facebook"

    logger.info(f"â„¹ï¸ [SESSION] ØªÙ… ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ù†ØµØ© '{main_platform}' Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… {user_id}.")

    if session:
        update_fields = {
            "last_contact_date": now_utc, "platform": main_platform,
            "profile.name": contact_data.get("name"), "profile.profile_pic": contact_data.get("profile_pic"),
            "status": "active"
        }
        sessions_collection.update_one({"_id": user_id}, {"$set": {k: v for k, v in update_fields.items() if v is not None}})
        logger.info(f"ğŸ”„ [SESSION] ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¬Ù„Ø³Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… {user_id}.")
        return sessions_collection.find_one({"_id": user_id})
    else:
        logger.info(f"ğŸ†• [SESSION] Ù…Ø³ØªØ®Ø¯Ù… Ø¬Ø¯ÙŠØ¯. Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ø´Ø§Ù…Ù„Ø© Ù„Ù‡: {user_id}")
        new_session = {
            "_id": user_id, "platform": main_platform,
            "profile": {"name": contact_data.get("name"), "first_name": contact_data.get("first_name"), "last_name": contact_data.get("last_name"), "profile_pic": contact_data.get("profile_pic")},
            "openai_thread_id": None, "tags": [f"source:{main_platform.lower()}"],
            "custom_fields": contact_data.get("custom_fields", {}),
            "conversation_summary": "", "status": "active",
            "first_contact_date": now_utc, "last_contact_date": now_utc
        }
        sessions_collection.insert_one(new_session)
        return new_session

# --- Ø¯ÙˆØ§Ù„ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø·ÙˆÙŠÙ„Ø© Ø§Ù„Ø£Ù…Ø¯ ---
async def summarize_and_save_conversation(user_id, thread_id):
    logger.info(f"ğŸ§  [MEMORY] Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© ØªÙ„Ø®ÙŠØµ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… {user_id}.")
    try:
        messages = await asyncio.to_thread(client.beta.threads.messages.list, thread_id=thread_id, limit=20)
        history = "\n".join([f"{msg.role}: {msg.content[0].text.value}" for msg in reversed(messages.data)])
        
        prompt = f"Please summarize the following conversation concisely in a few key points. This summary will be used as a memory for a chatbot. Focus on user needs, important details (like products they are interested in, their budget, contact info), and the last state of the conversation.\n\nConversation:\n{history}\n\nSummary:"

        response = await asyncio.to_thread(
            client.chat.completions.create,
            model="gpt-4.1-mini",
            messages=[{"role": "system", "content": prompt}]
        )
        summary = response.choices[0].message.content.strip()
        
        sessions_collection.update_one({"_id": user_id}, {"$set": {"conversation_summary": summary}})
        logger.info(f"âœ… [MEMORY] ØªÙ… ØªÙ„Ø®ÙŠØµ ÙˆØªØ­Ø¯ÙŠØ« Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… {user_id}.")
    except Exception as e:
        logger.error(f"âŒ [MEMORY] ÙØ´Ù„ ÙÙŠ ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… {user_id}: {e}", exc_info=True)

# --- Ø¯ÙˆØ§Ù„ OpenAI (Ù…ÙØ¹Ø¯Ù‘Ù„Ø© Ù„ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©) ---
async def get_assistant_reply(session, content, timeout=90):
    user_id = session["_id"]
    thread_id = session.get("openai_thread_id")
    summary = session.get("conversation_summary", "")
    logger.info(f"ğŸ¤– [ASSISTANT] Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø¯ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… {user_id}.")

    if not thread_id:
        logger.warning(f"ğŸ§µ [ASSISTANT] Ù„Ø§ ÙŠÙˆØ¬Ø¯ thread Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… {user_id}. Ø³ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ§Ø­Ø¯ Ø¬Ø¯ÙŠØ¯.")
        try:
            thread = await asyncio.to_thread(client.beta.threads.create)
            thread_id = thread.id
            sessions_collection.update_one({"_id": user_id}, {"$set": {"openai_thread_id": thread_id}})
            logger.info(f"âœ… [ASSISTANT] ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ®Ø²ÙŠÙ† thread Ø¬Ø¯ÙŠØ¯: {thread_id}")
        except Exception as e:
            logger.error(f"âŒ [ASSISTANT] ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ thread Ø¬Ø¯ÙŠØ¯: {e}", exc_info=True)
            return "âš ï¸ Ø¹ÙÙˆÙ‹Ø§ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©."

    enriched_content = content
    if summary:
        logger.info(f"ğŸ§  [MEMORY] ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø°Ø§ÙƒØ±Ø© Ø³Ø§Ø¨Ù‚Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…. Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§.")
        enriched_content = f"For your context, here is a summary of my previous conversations with this user: '{summary}'. Now, please respond to the user's new message(s): '{content}'"
    else:
        logger.info(f"ğŸ§  [MEMORY] Ù„Ø§ ØªÙˆØ¬Ø¯ Ø°Ø§ÙƒØ±Ø© Ø³Ø§Ø¨Ù‚Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù….")

    try:
        logger.info(f"ğŸ’¬ [ASSISTANT] Ø¥Ø¶Ø§ÙØ© Ø±Ø³Ø§Ù„Ø© Ø¥Ù„Ù‰ Thread {thread_id}: '{content}'")
        await asyncio.to_thread(client.beta.threads.messages.create, thread_id=thread_id, role="user", content=enriched_content)
        
        logger.info(f"â–¶ï¸ [ASSISTANT] Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ (Run) Ø¹Ù„Ù‰ Thread {thread_id}.")
        run = await asyncio.to_thread(client.beta.threads.runs.create, thread_id=thread_id, assistant_id=ASSISTANT_ID_PREMIUM)
        
        start_time = time.time()
        while run.status in ["queued", "in_progress"]:
            if time.time() - start_time > timeout:
                logger.error(f"â° [ASSISTANT] Timeout! Ø§Ø³ØªØºØ±Ù‚ Ø§Ù„Ù€ run {run.id} Ø£ÙƒØ«Ø± Ù…Ù† {timeout} Ø«Ø§Ù†ÙŠØ©.")
                return "âš ï¸ Ø­Ø¯Ø« ØªØ£Ø®ÙŠØ± ÙÙŠ Ø§Ù„Ø±Ø¯ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰."
            await asyncio.sleep(1)
            run = await asyncio.to_thread(client.beta.threads.runs.retrieve, thread_id=thread_id, run_id=run.id)
        
        if run.status == "completed":
            messages = await asyncio.to_thread(client.beta.threads.messages.list, thread_id=thread_id, limit=1)
            reply = messages.data[0].content[0].text.value.strip()
            logger.info(f"ğŸ—£ï¸ [ASSISTANT] Ø§Ù„Ø±Ø¯ Ø§Ù„Ø°ÙŠ ØªÙ… Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„ÙŠÙ‡: \"{reply}\"")
            return reply
        else:
            logger.error(f"âŒ [ASSISTANT] Ù„Ù… ÙŠÙƒØªÙ…Ù„ Ø§Ù„Ù€ run. Ø§Ù„Ø­Ø§Ù„Ø©: {run.status}. Ø§Ù„Ø®Ø·Ø£: {run.last_error}")
            return "âš ï¸ Ø¹ÙÙˆÙ‹Ø§ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙ†ÙŠ."
    except Exception as e:
        logger.error(f"âŒ [ASSISTANT] Ø­Ø¯Ø« Ø§Ø³ØªØ«Ù†Ø§Ø¡ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {e}", exc_info=True)
        return "âš ï¸ Ø¹ÙÙˆÙ‹Ø§ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹."

# --- Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ØºÙŠØ± Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø© ---
def send_manychat_reply_async(subscriber_id, text_message, platform):
    logger.info(f"ğŸ“¤ [SENDER] Ø¨Ø¯Ø¡ Ø¥Ø±Ø³Ø§Ù„ Ø±Ø¯ Ø¥Ù„Ù‰ {subscriber_id} Ø¹Ù„Ù‰ Ù…Ù†ØµØ© {platform}...")
    if not MANYCHAT_API_KEY:
        logger.error("âŒ [SENDER] Ù…ÙØªØ§Ø­ MANYCHAT_API_KEY ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯!")
        return

    url = "https://api.manychat.com/fb/sending/sendContent"
    headers = {"Authorization": f"Bearer {MANYCHAT_API_KEY}", "Content-Type": "application/json"}
    channel = "instagram" if platform == "Instagram" else "facebook"

    payload = {
        "subscriber_id": str(subscriber_id ),
        "data": {"version": "v2", "content": {"messages": [{"type": "text", "text": text_message.strip()}]}},
        "channel": channel,
    }

    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=20)
        response.raise_for_status()
        logger.info(f"âœ… [SENDER] ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ù„Ù‰ {subscriber_id} Ø¹Ø¨Ø± {channel}.")
    except requests.exceptions.HTTPError as e:
        error_text = e.response.text if e.response is not None else str(e)
        logger.error(f"âŒ [SENDER] ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø©: {e}. ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£: {error_text}")
    except Exception as e:
        logger.error(f"âŒ [SENDER] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„: {e}", exc_info=True)

# --- New helper: transcribe audio from a public URL (option C: only transcribe audio; images send as URLs)
def transcribe_audio_url(audio_url):
    """
    Downloads the audio from the given URL (simple GET) and calls OpenAI transcription.
    Returns the transcript string or None on failure.
    """
    try:
        logger.info(f"ğŸ”Š [TRANSCRIBE] ØªÙ†Ø²ÙŠÙ„ Ù…Ù„Ù Ø§Ù„ØµÙˆØª Ù…Ù† {audio_url} ...")
        resp = requests.get(audio_url, timeout=20)
        resp.raise_for_status()
        audio_bytes = resp.content
    except Exception as e:
        logger.error(f"âŒ [TRANSCRIBE] ÙØ´Ù„ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„ØµÙˆØª Ù…Ù† {audio_url}: {e}")
        return None

    try:
        # Use to_thread to avoid blocking main thread if OpenAI client is blocking
        transcription_resp = asyncio.run(asyncio.to_thread(
            client.audio.transcriptions.create, audio_bytes, "audio.webm", {"model":"gpt-4o-mini-transcribe"}))
        # The exact attribute depends on client; try common patterns
        if hasattr(transcription_resp, "text"):
            return transcription_resp.text
        if isinstance(transcription_resp, dict) and transcription_resp.get("text"):
            return transcription_resp.get("text")
        # fallback to string
        return str(transcription_resp)
    except Exception as e:
        logger.error(f"âŒ [TRANSCRIBE] ÙØ´Ù„ ØªÙØ±ÙŠØº Ø§Ù„ØµÙˆØª Ø¹Ø¨Ø± OpenAI: {e}", exc_info=True)
        return None

def schedule_assistant_response(user_id):
    lock = processing_locks.setdefault(user_id, threading.Lock())
    with lock:
        if user_id not in pending_messages or not pending_messages[user_id]:
            return
        
        user_data = pending_messages[user_id]
        session = user_data["session"]

        # --- Ø¬Ù…Ø¹ Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø®ØªÙ„ÙØ© Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ù†Øµ ÙˆØ§Ø­Ø¯ ---
        texts = user_data.get("texts", [])
        images = user_data.get("images", [])
        audios = user_data.get("audios", [])

        # Ø¯Ù…Ø¬ ÙƒÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø¬Ù…Ø¹Ø© ÙÙŠ Ù†Øµ ÙˆØ§Ø­Ø¯ Ù…Ø¹ ÙÙˆØ§ØµÙ„ Ø£Ø³Ø·Ø±
        combined_parts = []
        if texts:
            combined_parts.append("\n".join(texts))

        # Ø£Ø¶Ù Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØµÙˆØ± (URLs) ÙƒØ³Ø·Ø± ÙŠÙ…ÙƒÙ† Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø£Ù† ÙŠØ±Ø¬Ø¹ Ø¥Ù„ÙŠÙ‡
        for img_url in images:
            combined_parts.append(f"[Image]: {img_url}")

        # ØªÙØ±ÙŠØº Ø§Ù„Ø£ØµÙˆØ§Øª: Ù†Ø¹Ù…Ù„ ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù†Øµ ÙˆÙ†Ø¶ÙŠÙÙ‡Ø§
        for audio_url in audios:
            transcript = transcribe_audio_url(audio_url)
            if transcript:
                combined_parts.append(f"[Audio transcript from {audio_url}]: {transcript}")
            else:
                combined_parts.append(f"[Audio at {audio_url}]: (failed to transcribe)")

        combined_content = "\n\n".join(combined_parts).strip()
        logger.info(f"âš™ï¸ [PROCESSOR] Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø¬Ù…Ø¹ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… {user_id}: '{combined_content}'")

        # Call assistant (unchanged flow) by running the async function from sync
        reply_text = asyncio.run(get_assistant_reply(session, combined_content))
        
        if reply_text:
            send_manychat_reply_async(user_id, reply_text, platform=session.get("platform", "Facebook"))
            
            thread_id = session.get("openai_thread_id")
            if thread_id:
                logger.info(f"ğŸ—“ï¸ [MEMORY] Ø¬Ø¯ÙˆÙ„Ø© Ø¹Ù…Ù„ÙŠØ© ØªÙ„Ø®ÙŠØµ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… {user_id}.")
                summary_thread = threading.Thread(target=lambda: asyncio.run(summarize_and_save_conversation(user_id, thread_id)))
                summary_thread.start()

        # cleanup
        if user_id in pending_messages: del pending_messages[user_id]
        if user_id in message_timers: del message_timers[user_id]
        logger.info(f"ğŸ—‘ï¸ [PROCESSOR] ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… {user_id}.")

# --- ØªØ¹Ø¯ÙŠÙ„ add_to_processing_queue Ù„Ø¯Ø¹Ù… Ø§Ù„Ù†Øµ + ØµÙˆØ± + ØµÙˆØª ---
def add_to_processing_queue(session, payload):
    """
    payload ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ†:
      - Ù†Øµ string -> ÙŠØ¶Ø§Ù Ø¥Ù„Ù‰ texts
      - dict -> {'text': ..., 'image_url': ..., 'audio_url': ...}
    """
    user_id = session["_id"]

    # ensure pending structure exists
    if user_id not in pending_messages or not pending_messages[user_id]:
        pending_messages[user_id] = {"texts": [], "images": [], "audios": [], "session": session}
    else:
        # always update session reference (fresh)
        pending_messages[user_id]["session"] = session

    # cancel previous timer if exists
    if user_id in message_timers:
        try:
            message_timers[user_id].cancel()
            logger.info(f"â³ [DEBOUNCE] ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ù…Ø¤Ù‚Øª Ø§Ù„Ù‚Ø¯ÙŠÙ… Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… {user_id} Ù„Ø£Ù†Ù‡ Ø£Ø±Ø³Ù„ Ø±Ø³Ø§Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø©.")
        except Exception:
            pass

    # accept both simple strings and dict payloads
    if isinstance(payload, str):
        pending_messages[user_id]["texts"].append(payload)
    elif isinstance(payload, dict):
        text = payload.get("text")
        image_url = payload.get("image_url")
        audio_url = payload.get("audio_url")
        if text:
            pending_messages[user_id]["texts"].append(text)
        if image_url:
            pending_messages[user_id]["images"].append(image_url)
        if audio_url:
            pending_messages[user_id]["audios"].append(audio_url)
    else:
        # unknown type, ignore
        logger.warning(f"âš ï¸ [QUEUE] payload type unknown for user {user_id}: {type(payload)}")

    logger.info(f"â• [QUEUE] ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© Ù…Ø­ØªÙˆÙ‰ Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… {user_id}. "
                f"counts: texts={len(pending_messages[user_id]['texts'])}, "
                f"images={len(pending_messages[user_id]['images'])}, audios={len(pending_messages[user_id]['audios'])}")

    # start a new debounce timer
    timer = threading.Timer(BATCH_WAIT_TIME, schedule_assistant_response, args=[user_id])
    message_timers[user_id] = timer
    timer.start()
    logger.info(f"â³ [DEBOUNCE] Ø¨Ø¯Ø¡ Ù…Ø¤Ù‚Øª Ø¬Ø¯ÙŠØ¯ Ù„Ù…Ø¯Ø© {BATCH_WAIT_TIME} Ø«Ø§Ù†ÙŠØ© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… {user_id}.")

# --- ÙˆÙŠØ¨ Ù‡ÙˆÙƒ ManyChat (Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…ÙˆØ­Ø¯Ø©) ---
@app.route("/manychat_webhook", methods=["POST"])
def manychat_webhook_handler():
    logger.info("ğŸ“ [WEBHOOK] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø·Ù„Ø¨ Ø¬Ø¯ÙŠØ¯.")
    auth_header = request.headers.get('Authorization')
    if not MANYCHAT_SECRET_KEY or auth_header != f'Bearer {MANYCHAT_SECRET_KEY}':
        logger.critical("ğŸš¨ [WEBHOOK] Ù…Ø­Ø§ÙˆÙ„Ø© ÙˆØµÙˆÙ„ ØºÙŠØ± Ù…ØµØ±Ø­ Ø¨Ù‡Ø§!")
        return jsonify({"status": "error", "message": "Unauthorized"}), 403
    
    data = request.get_json()
    if not data or not data.get("full_contact"):
        logger.error("âŒ [WEBHOOK] CRITICAL: 'full_contact' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©.")
        return jsonify({"status": "error", "message": "Invalid data"}), 400

    session = get_or_create_session_from_contact(data["full_contact"])
    if not session:
        logger.error("âŒ [WEBHOOK] ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø£Ùˆ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù„Ø³Ø©.")
        return jsonify({"status": "error", "message": "Failed to create session"}), 500

    contact_data = data.get("full_contact", {})

    # --- extract text, image, audio (compatible with common ManyChat shapes) ---
    last_input = contact_data.get("last_text_input") or contact_data.get("last_input_text") or data.get("last_input")
    image_url = None
    audio_url = None

    # attachments variants
    att = contact_data.get("last_attachment") or contact_data.get("attachment") or data.get("last_attachment")
    if isinstance(att, dict):
        att_type = att.get("type")
        if att_type == "image":
            image_url = att.get("url") or att.get("file_url")
        elif att_type == "audio":
            audio_url = att.get("url") or att.get("file_url")

    # other fields that some ManyChat variants use
    if not image_url:
        attachments = contact_data.get("attachments") or data.get("attachments")
        if isinstance(attachments, list):
            for a in attachments:
                if a.get("type") == "image":
                    image_url = a.get("url") or a.get("file_url")
                    break

    if not audio_url:
        audio_url = contact_data.get("last_audio_url") or contact_data.get("audio_url") or data.get("last_audio_url")

    # If nothing found, respond no_input_received
    if not any([last_input, image_url, audio_url]):
        logger.warning("[WEBHOOK] Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ù†ØµÙŠ/ØµÙˆØ±Ø©/ØµÙˆØª Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©.")
        return jsonify({"status": "no_input_received"})

    # Build payload dict and enqueue (we use dict to allow images/audio)
    payload = {"text": last_input, "image_url": image_url, "audio_url": audio_url}
    add_to_processing_queue(session, payload)
    
    logger.info("âœ… [WEBHOOK] ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©. Ø¥Ø±Ø¬Ø§Ø¹ ØªØ£ÙƒÙŠØ¯ Ø§Ø³ØªÙ„Ø§Ù… ÙÙˆØ±ÙŠ.")
    return jsonify({"status": "received"})

# --- Ù†Ù‚Ø·Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ---
@app.route("/")
def home():
    return "âœ… Bot is running in Unified Mode with Long-Term Memory (v19 - Final)."

if __name__ == "__main__":
    logger.info("ğŸš€ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¬Ø§Ù‡Ø² Ù„Ù„ØªØ´ØºÙŠÙ„. ÙŠØ±Ø¬Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø§Ø¯Ù… WSGI (Ù…Ø«Ù„ Gunicorn) Ù„ØªØ´ØºÙŠÙ„Ù‡ ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬.")
